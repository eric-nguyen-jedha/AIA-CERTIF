# AIA - BLOC_04 : Projet MÃ©tÃ©o - ML Pipeline

## PrÃ©sentation en ligne de l'intÃ©gralitÃ© du projet

ğŸš€ [Bloc_04 | PROJET MÃ‰TÃˆO | PrÃ©sentation PPT](https://docs.google.com/presentation/d/1nWi3Q9N6SFRfRQldj1ZbB49OlgcXWEltxNtJOjyxBNA/edit?usp=sharing) \
ğŸ“ [Bloc_04 | PROJET MÃ‰TÃˆO | Backup sur GitHub]()


Un projet de machine learning pour la prÃ©diction mÃ©tÃ©orologique sur les grandes villes de France avec une interface Streamlit, des pipelines Airflow et une architecture Docker.

## ğŸš€ Vue d'ensemble

Ce projet implÃ©mente un pipeline complet de machine learning pour prÃ©dire les conditions mÃ©tÃ©orologiques Ã  Paris. Il inclut :

- **ModÃ¨le ML** : Classification des conditions mÃ©tÃ©o (XGBoost)
- **Interface web** : Application Streamlit avec carte interactive
- **Orchestration** : Pipelines Airflow pour l'entraÃ®nement et la prÃ©diction
- **MLOps** : IntÃ©gration MLflow pour le suivi des expÃ©riences
- **Tests** : Suite de tests automatisÃ©s avec pytest

## ğŸ“ Structure du projet

```

â””â”€â”€ AIRFLOW/
â”œâ”€â”€ config/
â”‚ â””â”€â”€ airflow.cfg # Configuration principale d'Airflow
â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ evidently_datacheck.py # DAG de validation des donnÃ©es avec Evidently
â”‚ â”œâ”€â”€ meteo_paris.py # DAG principal pour les donnÃ©es mÃ©tÃ©o Paris
â”‚ â”œâ”€â”€ paris_meteo_ml_pipeline.py # DAG pour le pipeline ML (entraÃ®nement, etc.)
â”‚ â””â”€â”€ realtime_prediction_forecast.py # DAG pour les prÃ©dictions en temps rÃ©el
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ data_driftft.ipynb # Notebook dâ€™analyse de dÃ©rive des donnÃ©es
â”‚ â”œâ”€â”€ weather_paris_drift_report.html # Rapport HTML de dÃ©rive
â”‚ â”œâ”€â”€ weather_paris_humidity_analysis.html # Analyse dâ€™humiditÃ©
â”‚ â”œâ”€â”€ weather_paris_pressure_analysis.html # Analyse de pression
â”‚ â”œâ”€â”€ weather_paris_temp_analysis.html # Analyse de tempÃ©rature
â”‚ â”œâ”€â”€ weather_paris_test_suite.html # Suite de tests HTML
â”‚ â”œâ”€â”€ weather_paris_wind_speed_analysis.html # Analyse de vitesse du vent
â”‚ â””â”€â”€ weather_paris.csv # DonnÃ©es brutes mÃ©tÃ©o Paris
â”œâ”€â”€ docker-compose.yaml # Fichier de configuration Docker Compose
â”œâ”€â”€ Dockerfile # Dockerfile pour lâ€™environnement Airflow
â”œâ”€â”€ plugins/
â”‚ â”œâ”€â”€ s3_to_postgres.py # Plugin personnalisÃ© : transfert S3 â†’ PostgreSQL
â”‚ â””â”€â”€ requirements.txt # DÃ©pendances spÃ©cifiques aux plugins

â”œâ”€â”€ STREAMLIT/             # Application web Streamlit
â”œâ”€â”€ MLFLOW/                # Configuration MLflow
â”œâ”€â”€ data/                  # DonnÃ©es mÃ©tÃ©o
â”œâ”€â”€ dags_ml/ # DAGs Airflow spÃ©cifiques au pipeline ML
â”‚ â”œâ”€â”€ realtime_prediction_forecast.py    # Tests unitaires du pipeline de donnÃ©es
â”‚ â””â”€â”€ paris_meteo_ml_pipeline.py        # Tests unitaires du pipeline de donnÃ©es
â”œâ”€â”€ plugins/ # Plugins Airflow personnalisÃ©s (ajoutÃ©s au PYTHONPATH)
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â”œâ”€â”€ full_paris_meteo_ml_forcast_dag.py # Fichier de test pour la structure complÃ¨te du DAG ML
â”‚ â”‚ â”œâ”€â”€ meteo_paris.py # Test ou utilitaire liÃ© au DAG mÃ©tÃ©o
â”‚ â”‚ â””â”€â”€ weather_utils.py # Fonctions utilitaires partagÃ©es pour les DAGs mÃ©tÃ©o
â”‚ â”œâ”€â”€ integration/
â”‚ â”‚ â””â”€â”€ test_dag_structure.py # Test dâ€™intÃ©gration (exÃ©cutÃ© avec le marqueur "integration")
â”‚ â”œâ”€â”€ ml/
â”‚ â”‚ â”œâ”€â”€ test_training_pipeline.py # Tests unitaires du pipeline ML
â”‚ â”‚ â”œâ”€â”€ test_weather_dags.py # Tests unitaires des DAGs mÃ©tÃ©o
â”‚ â”‚ â””â”€â”€ validate_dags.py # Script de validation syntaxique des DAGs (appelÃ© dans "Validate DAGs")
â”‚ â””â”€â”€ unit/
â”‚ â”œâ”€â”€ test_csv_to_s3_upload.py # Test unitaire : upload CSV vers S3
â”‚ â”œâ”€â”€ test_fetch_weather_data.py # Test unitaire : rÃ©cupÃ©ration des donnÃ©es mÃ©tÃ©o
â”‚ â”œâ”€â”€ test_setup_aws_environment.py # Test unitaire : configuration AWS
â”‚ â”œâ”€â”€ test_transform_and_append_weather_data.py # Test unitaire : transformation des donnÃ©es
â”‚ â””â”€â”€ conftest.py # Configuration commune pour pytest
â”œâ”€â”€ requirements.txt # DÃ©pendances Python du projet
â”œâ”€â”€ Dockerfile            # Configuration Docker
â”œâ”€â”€ .env                  # Ã  remplir par vos credentials
â””â”€â”€ Jenkinsfile           # Pipeline CI/CD
```
## ğŸ“ SchÃ©ma Mermaid
```mermaid
graph TD

    subgraph Jenkins["Jenkins (CI/CD)"]
        direction TB
        J_Tests_Units["Tests Units"] --> J_Tests_Int["Tests Int."]
        J_Tests_Int --> J_Trigger_Airflow["Trig. Airflow"]
        J_Trigger_Airflow --> J_Email_Not["Email not."]
    end

    subgraph Airflow["Airflow (Orchestration)"]
        direction LR
        A_DAGs["DAGs"] --> A_Data_Pull["Data Pull"]
        A_Data_Pull --> A_Data_Check["Data Check"]
        A_Data_Check --> A_ML_Training["ML Training"]
        A_ML_Training --> A_Predict["Predict"]
        A_Predict --> A_Email_Not["Email not."]
    end

    subgraph MLflow["MLflow (Model Management)"]
        direction LR
        M_Metrics["Metrics"] --> M_PostgreSQL["PostgreSQL + NEON"]
        M_Artifact_Model["Artifact Model"] --> M_S3_Model["S3 Model"]
    end

    subgraph External["External Services"]
        O_OpenWeatherAPI["OpenWeather API"]
        S_S3_History["S3 Data History"]
        S_S3_Predict["S3 Predict"]
        U_Streamlit["Streamlit App"]
        U_Users["Users"]
    end

    %% Connections
    Jenkins -->|Trigger| Airflow
    Jenkins -->|Notify| TEAM_DATA_J["TEAM DATA"]

    Airflow -->|Pull data from| O_OpenWeatherAPI
    Airflow -->|Store history in| S_S3_History
    Airflow -->|Log metrics to| MLflow
    Airflow -->|Save model to| MLflow
    Airflow -->|Send predictions to| S_S3_Predict
    Airflow -->|Notify| TEAM_DATA_A["TEAM DATA"]

    MLflow -->|Store metrics in| M_PostgreSQL
    MLflow -->|Store model in| M_S3_Model

    S_S3_Predict -->|Feed| U_Streamlit
    U_Streamlit -->|Serve to| U_Users

    %% Styling for grayscale
    classDef gray fill:#f0f0f0,stroke:#666,stroke-width:2px;
    classDef darkGray fill:#d0d0d0,stroke:#444,stroke-width:2px;
    classDef mediumGray fill:#e0e0e0,stroke:#555,stroke-width:2px;

    class Jenkins,Airflow,MLflow,External gray
    class J_Tests_Units,J_Tests_Int,J_Trigger_Airflow,J_Email_Not darkGray
    class A_Data_Pull,A_Data_Check,A_ML_Training,A_Predict,A_Email_Not mediumGray
    class M_Metrics,M_Artifact_Model,M_PostgreSQL,M_S3_Model mediumGray
    class O_OpenWeatherAPI,S_S3_History,S_S3_Predict,U_Streamlit,U_Users darkGray

```

## ğŸ“Š DonnÃ©es

Le projet utilise le fichier `data/weather_paris.csv` contenant :
- TempÃ©rature, humiditÃ©, pression
- Conditions mÃ©tÃ©orologiques
- DonnÃ©es historiques de Paris

## ğŸ›  Technologies utilisÃ©es

- **ML** : scikit-learn, XGBoost, pandas, numpy
- **Interface** : Streamlit, folium (cartes)
- **Orchestration** : Apache Airflow
- **MLOps** : MLflow
- **Cloud** : AWS S3, boto3
- **Tests** : pytest, great_expectations
- **DevOps** : Docker, Jenkins


## ğŸ¯ Utilisation


### 1. Collecte de donnÃ©es pour former le DataSet d'entrainement, via l'API OPENWEATHER
```
dags/meteo_paris.py
```


### 1. EntraÃ®nement du modÃ¨le

```bash
# Version sans MLflow
python app/paris_meteo_no_mlflow.py

# Version avec fusion des donnÃ©es
python app/paris_meteo_fusion.py
```


### 2. Tests
```bash
# Lancer tous les tests
pytest tests/

# Tests spÃ©cifiques
pytest tests/test_paris_meteo_no_mlflow.py
```

### 3. Pipelines Airflow

```bash
cd airflow
docker-compose up -d
```

AccÃ©dez Ã  `http://localhost:8080` pour gÃ©rer les DAGs :


### 4. Airflow Dags

```
â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ meteo_paris.py # 1. Collecte des donnÃ©es mÃ©tÃ©o pour former le DATASET, collecte que pour la ville de Paris
â”‚ â”œâ”€â”€ evidently_datacheck.py # 2. DAG de validation des donnÃ©es avec Evidently
â”‚ â”œâ”€â”€ paris_meteo_ml_pipeline.py # 3. DAG pour le pipeline ML (entraÃ®nement, etc.)
â”‚ â””â”€â”€ realtime_prediction_forecast.py # 4. DAG pour les prÃ©dictions en temps rÃ©el
```

### 5. Tests Jenkins

```
â”œâ”€â”€ dags_ml/ # DAGs Airflow spÃ©cifiques au pipeline ML
â”‚ â”œâ”€â”€ realtime_prediction_forecast.py    # Tests unitaires du pipeline de donnÃ©es
â”‚ â””â”€â”€ paris_meteo_ml_pipeline.py        # Tests unitaires du pipeline de donnÃ©es
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â”œâ”€â”€ full_paris_meteo_ml_forcast_dag.py # Fichier de test pour la structure complÃ¨te du DAG ML
â”‚ â”‚ â”œâ”€â”€ meteo_paris.py # Test ou utilitaire liÃ© au DAG mÃ©tÃ©o
â”‚ â”‚ â””â”€â”€ weather_utils.py # Fonctions utilitaires partagÃ©es pour les DAGs mÃ©tÃ©o
â”‚ â”œâ”€â”€ integration/
â”‚ â”‚ â””â”€â”€ test_dag_structure.py # Test dâ€™intÃ©gration (exÃ©cutÃ© avec le marqueur "integration")
â”‚ â”œâ”€â”€ ml/
â”‚ â”‚ â”œâ”€â”€ test_training_pipeline.py # Tests unitaires du pipeline ML
â”‚ â”‚ â”œâ”€â”€ test_weather_dags.py # Tests unitaires des DAGs mÃ©tÃ©o
â”‚ â”‚ â””â”€â”€ validate_dags.py # Script de validation syntaxique des DAGs (appelÃ© dans "Validate DAGs")
â”‚ â””â”€â”€ unit/
â”‚ â”œâ”€â”€ test_csv_to_s3_upload.py # Test unitaire : upload CSV vers S3
â”‚ â”œâ”€â”€ test_fetch_weather_data.py # Test unitaire : rÃ©cupÃ©ration des donnÃ©es mÃ©tÃ©o
â”‚ â”œâ”€â”€ test_setup_aws_environment.py # Test unitaire : configuration AWS
â”‚ â”œâ”€â”€ test_transform_and_append_weather_data.py # Test unitaire : transformation des donnÃ©es
â”‚ â””â”€â”€ conftest.py # Configuration commune pour pytest
```


## ğŸŒŸ FonctionnalitÃ©s

- âœ… PrÃ©diction des conditions mÃ©tÃ©o (Clear, Clouds, Rain, etc.)
- âœ… Interface web interactive avec carte
- âœ… Pipelines automatisÃ©s d'entraÃ®nement
- âœ… Suivi des expÃ©riences ML
- âœ… Tests automatisÃ©s (Unit et Integration)
- âœ… DÃ©ploiement Docker
- âœ… IntÃ©gration CI/CD

## ğŸ”§ Configuration

1. **Variables d'environnement** : CrÃ©er un fichier `.env` avec vos clÃ©s API
2. **MLflow** : Configurer l'URI de tracking dans les scripts
3. **AWS** : Configurer les credentials pour S3

> âš ï¸ Le test de lâ€™opÃ©rateur `S3ToPostgresOperator` a Ã©tÃ© **exclu des tests unitaires** car il dÃ©pend dâ€™Airflow et nâ€™est pas exÃ©cutable dans un environnement CI isolÃ©.

---

## ğŸ§ª Tests unitaires

- Couvrent **100 % de la logique mÃ©tier** (`fetch`, `transform`, `upload S3`)
- Utilisent des **mocks** pour simuler :
  - `requests.get`
  - `airflow.models.Variable.get`
  - `S3Hook`
  - `open()`, `os.path.exists`, etc.
- **Ne dÃ©pendent pas dâ€™Airflow** â†’ exÃ©cutables sous Jenkins

---

## ğŸ› ï¸ Configuration CI (Jenkins)

- Utilise un conteneur Docker `python:3.10-slim`
- Installe les dÃ©pendances via `requirements.txt`
- ExÃ©cute **uniquement les tests unitaires**
- Publie les rapports HTML et JUnit

> âœ… Aucune connexion Airflow, base de donnÃ©es ou AWS nâ€™est requise en CI.

---

## ğŸ“¦ DÃ©pendances minimales (`requirements.txt`)

```txt
pandas
requests
pytest
pytest-html
boto3

```

## ğŸ“Š Gestion des warnings

### pytest.ini
[tool:pytest]
filterwarnings =
    ignore::FutureWarning

## â–¶ï¸ Test dans Jenkins
- version de Jenkins : 2.516.3-1
- Blue Ocean : 1.27.23
## â–¶ï¸ Lancement de Jenkins
- docker stop jenkins-blueocean
- docker rm jenkins-blueocean

> Relancer le container (mapper sur le port 9090 pour Ã©viter les conflits avec airflow 8080 / Mlflow 8081)

```
docker run --name jenkins-blueocean -d \
  --restart=unless-stopped \
  -p 9090:8080 -p 50000:50000 \
  -v jenkins-data:/var/jenkins_home \
  -v /var/run/docker.sock:/var/run/docker.sock \
  myjenkins-blueocean:2.516.3-1

```
## ğŸ“© SMPT de Airflow est configurÃ© avec GMAIL
- dans l'Admin/Connection : configurer le SMTP avec le port : 587

```
# Utilisation du smtplib.SMTP
with smtplib.SMTP(smtp_host, smtp_port) as server:
            if use_tls:
                server.starttls()
            server.login(conn.login, conn.password)
            server.send_message(msg)
```            

## ğŸ“© SMPT de Jenkins est configurÃ© avec GMAIL
- dans l'admin de Jenkins : configurer le SMTP ainsi que l'Extended Email

## DÃ©clenchement d'Airflow par Jenkins (alternative Ã  l'API)
- DÃ©clenchement via CLI- mÃªme rÃ©seau 
- Installation du Client Docker dans Jenkins

## Lancement de MLFLOW LOCAL sur Minikube (si besoin)
- Port Forward : kubectl port-forward svc/mlflow-service 8081:8081


## ğŸ“ Licence

Ce projet est sous licence MIT.
